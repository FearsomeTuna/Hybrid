DATA:
  # data_root: root folder of dataset (within SAN folder)
  data_root: dataset/imagenet
  # dataset_init: defines the type of source data to initialize dataset:
  # - image_folder: initializes using torchvision.datasets.ImageFolder. Expects folders 'train', 'val', and possibly 'test'
  # - txt_mappings: initializes from txt mappings that include image path and class index on each line.
  #                 Expects train.txt, val.txt and mapping.txt files.
  # Transforms for train set (random augmentations) will be performed at runtime.
  # Transforms performed on val set are resize to 256x256 followed by center crop (224x224).
  dataset_init: txt_mappings
  # data_name: seemingly unused
  data_name: imagenet
  # classes: number of classes
  classes: 1000
  # mean: dataset mean for each input channel.
  mean: [0.485, 0.456, 0.406]
  # std: dataset standard deviation for each input channel.
  std: [0.229, 0.224, 0.225]


TRAIN:
  # layers: number of blocks used in each stage of model.
  layers: [2, 1, 2, 4, 1]
  # layer_types: List indicating base block type for each stage. Each element must be either 'san', 'res', or 'nl'.
  # Length must be equal to 'layers' config.
  layer_types: [san, san, san, san, san]
  # sa_type: san architecture type. 0 is pairwise, 1 is patchwise. Only used if 'layer_types' includes at least one san block stage.
  sa_type: 0
  # widths: used only on hybrid arch. indicates the output channel dimension of each stage. Length must be equal to 'layers' config.
  widths: [64, 256, 512, 1024, 2048]
  # added_nl_blocks: list indicating amount of non-local blocks to add to each stage. Each stage must have equal or less non-local
  # blocks than main type of block. List length must be equal to 'layers' config.
  added_nl_blocks: [0, 0, 0, 0, 0]
  # ignore_label: allows a class index to be ignored
  ignore_label: 2000
  # train_gpu: list of gpus to be used, requires correct distributed configurations (see Distributed section below) to have effect.
  train_gpu: [0, 1, 2, 3, 4, 5, 6, 7]
  # workers: data loader workers
  workers: 32 
  # batch_size: batch size for training
  batch_size: 256
  # batch_size_val: batch size for validation during training, memory and speed tradeoff
  batch_size_val: 128
  # base_lr: base learning rate (scheduler changes learning rate over time)
  base_lr: 0.1
  # epochs: number of epochs
  epochs: 100
  # start_epoch: starting epoch number. Affects train sampler and logs. Will be set automatically from checkpoint if 'resume' config is set.
  start_epoch: 0
  # step_epochs: steps at which learning rate is changed. Used only when 'scheduler' config is set to 'step'.
  step_epochs: [30, 60, 90]
  # label_smoothing: Defines label smoothing factor for training. Cross entropy loss tipically considers the ground truth for
  # each class to be either 0 or 1 (each sample corresponds exactly to one class). For various reasons,
  # it can be beneficial to consider a 'smooth' version of that ground truth.
  # If 'label_smoothing' and 'mixup_alpha' configs are undefined, torch.nn.CrossEntropyLoss is used.
  # If 'label_smoothing' is defined, but not 'mixup_alpha', a smooth loss is used with epsilon equal
  # to label_smoothing config.
  # If 'mixup_alpha' is defined, a mixup loss is used (augmentation technique proposed in 'mixup: Beyond Empirical Risk Minimization')
  # with epsilon equal to label_smoothing config (zero if not defined).
  label_smoothing: 0.1
  # mixup_alpha: if defined, performs mixup data augmentation (input images become the mix of two images).
  # This augmentation technique whas proposed in 'mixup: Beyond Empirical Risk Minimization'.
  # The ratio 'lam' that defines how much is taken from each image is defined from a beta
  # distribution with both shape parameters set to mixup_alpha config. Loss is calculated
  # as a weighted sum of each independent loss, ie the loss between the mixup image output and the first
  # image target class, and between the mixup output image and the second image target class,
  # where the ratio is also 'lam'.
  # This mixup loss can also be subject to label smoothing when 'label_smoothing' config is defined.
  mixup_alpha:
  # scheduler: scheduler used. This varies the learning rate over time (epochs). Can be 'step' or 'cosine'.
  scheduler: cosine
  # momentum: momentum used for optimizer
  momentum: 0.9
  # weight_decay: weight decay used for optimizer
  weight_decay: 0.0001
  # manual_seed: If defined, sets the initial seed to be used for all pseudo random tasks. Mainly for replicability.
  manual_seed:
  # print_freq: results will be printed to log every 'print_freq' steps within the epoch.
  print_freq: 10
  # save_freq: checkpoint will be saved every 'save_freq' epochs. Up to 2 checkpoints are kept at any point,
  # in addition to the best epoch run, that will be saved separately.
  save_freq: 1
  # save_path: path that models, log and tensorboard data will be saved to.
  save_path: exp/imagenet/san10_pairwise/model
  # weight: path to initial weight (default: none)
  weight:
  # resume: path to latest checkpoint (default: none)
  resume:
  # time_breakdown: if true, will breakdown time info into:
  # - time: total iteration time
  # - Data: time to load data from dataloader/dataset object (maybe affected by num of workers)
  # - Transfer: transfer time from cpu to gpu
  # - Batch: forward and backward pass
  # - Metric: time spent calculating metrics
  # This will sync execution of some CUDA kernels with torch.cuda.syncronize.
  # Note that this forced syncronization may slow down training.
  # Note that execution time depends on harware and current active processes, and
  # may still not be precise due to these and other syncing proceses, like multi gpu one, which may 'hide' or overlap one another.
  # These measurement are made from the main gpu process.
  # If false, only Time and Data times are recorded.
  time_breakdown: False
  # evaluate: unused.
  evaluate: True  
# Distributed: Configs for distributed execution. See pytorch's DistributedDataParallel documentation.
# To have any effect these configurations require the following:
# - length of 'train_gpu' config list to be > 1.
# - either 'multiprocessing_distributed' config to be true, or worl_size > 1.
# These configs allow training taking place in potentially several nodes (ie. individual machines, servers), each with same amount of GPUs.
Distributed:
  # dist_url: a URL string which indicates where/how to discover peers.
  # If multiprocessing_distributed is True, will be overriden with 'tcp://127.0.0.1:{free_port}'
  # where {free_port} is a free port on the system.
  dist_url: tcp://127.0.0.1:6789
  # dist_backend: distributed backend to use, only tested with nccl
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  # world_size: Number of distributed nodes. If -1, will be taken from environment variable 'WORLD_SIZE'
  # note: within scripts, args.world_size will be reassigned to be the total amount of gpus in distributed
  # environment.
  world_size: 1
  # rank: current node assigned index. If -1 and multiprocessing_distributed==True, and dist_url=="env://",
  # rank will be overriden from environment variable 'RANK'.
  # note: within scripts, args.rank will be reassigned to be the current process index, where each gpu across all
  # nodes will have a different process index within the group.
  rank: 0

TEST:
  # use_val_set: if True, use validation set as test set, instead of a separate set,
  # when running test scripts (NOT to confuse with validation during trainig).
  use_val_set: True
  test_gpu: [0]
  test_workers: 10
  batch_size_test: 100
  model_path: exp/imagenet/san10_pairwise/model/model_best.pth